"""Key Facts QA use case."""

import ast
import asyncio
import json
import re
from json import JSONDecodeError
from typing import Any

import numpy as np
import pandas as pd

from ada.components.db.pg_connector import PGConnector
from ada.components.db.sf_connector import SnowflakeClient
from ada.components.llm_models.generic_calls import (
    generate_chat_response_with_chain,
    generate_embeddings_from_string,
)
from ada.use_cases.key_facts.configuration import Configuration
from ada.use_cases.key_facts.entity_lookup import EntityLookup
from ada.use_cases.key_facts.prompts_v3 import (
    dax_response_generation_prompt,
    generate_dax_one_prompt,
    report_mapping_prompt,
)
from ada.use_cases.key_facts.utils import (
    extract_dax_entities,
    get_dax_patterns,
    get_reports_description,
)
from ada.use_cases.key_facts.open_world_response import open_world_response_generation
from ada.use_cases.key_facts_chatbot.call_keyfact_chatbot import fetch
from ada.use_cases.key_facts_chatbot.configs import kf_chatbot_config
from ada.utils.config.config_loader import read_config
from ada.utils.format.format import exception_response
from ada.utils.logs.logger import get_logger
from ada.utils.logs.time_logger import log_time

log = get_logger("key_facts-v3")
key_facts_config = read_config("use-cases.yml")["key_facts_v3"]


@log_time
def generate_dax_query(
    user_query: str,
    few_shot_examples: dict,
    category: str,
    category_configuration: Configuration,
) -> str:
    """
    Using Genai to create a DAX query that responds to a user query
    based on the given category and query-DAX mapping.

    Args:
        user_query: query from user to use for generating dax query
        few_shot_examples: dict with examples for prompts
        category: category from UI
        category_configuration: category-specific configuration inputs

    Returns:
        GenAI generated DAX query in Str format

    """
    data_model = category_configuration.configuration_dict["data_model"]
    measure_description = category_configuration.configuration_dict["measures_description"]
    filters_description = category_configuration.configuration_dict["filters_description"]

    category_filter_details = category_configuration.configuration_dict["category_filter"]
    category_filter_level = (
        ast.literal_eval(category_filter_details)["filter"]
        if isinstance(category_filter_details, str)
        else category_filter_details["filter"]
    )
    log.info("category_filter_level : %s", category_filter_level)

    few_shot_questions = few_shot_examples["few_shot_questions"]
    few_shot_query_filtered = few_shot_examples["few_shot_query_filtered"]

    prompt = generate_dax_one_prompt(
        data_model=data_model,
        measure_description=measure_description,
        filters_description=filters_description,
        few_shot_questions=few_shot_questions,
        few_shot_query_filtered=few_shot_query_filtered,
        category=category,
        user_question=user_query,
        category_filter_level=category_filter_level,
    )
    # TODO : Additional layer to ensure we have output from only Task4
    return generate_chat_response_with_chain(
        prompt=prompt,
        model=key_facts_config["common_config"]["model"]["model_name"],
    )


@log_time
def enhance_dax_query(llm_generated_dax_query: str, pg_db_conn: PGConnector, category: str) -> str:
    """
    Enhance a DAX query by replacing extracted entities with their actual values.

    This function processes the given DAX query string, extracts entities,
    performs a lookup to find the actual values from a database, and
    replaces the entities in the original query based on predefined patterns.

    Parameters:
        llm_generated_dax_query (str): The DAX query generated by llm.
        pg_db_conn (PGConnector): PGConnector for database access.
        category (str): The category used to filter.

    Returns:
        str: The enhanced DAX query with entities replaced by their actual values.
    """
    extracted_entities = extract_dax_entities(llm_generated_dax_query)
    log.info("Entities found in dax query : %s", extracted_entities)

    enhanced_dax_query = llm_generated_dax_query
    if extracted_entities:
        entity_lookup = EntityLookup(pg_db_conn, category)
        actual_entities = entity_lookup.run_lookup(extracted_entities)
        log.info("Lookup values for extracted entities : %s", actual_entities)
        patterns = get_dax_patterns()

        for key, entity_list in actual_entities.items():
            for entity_obj in entity_list:
                if entity_obj.actual_value:
                    replace_text = (
                        patterns[key]["replace"]
                        .replace("<replace>", entity_obj.actual_value)
                        .replace('""', '"')
                    )
                    enhanced_dax_query = re.sub(
                        patterns[key]["regex"],
                        replace_text,
                        enhanced_dax_query,
                        flags=re.IGNORECASE,
                    )
    return enhanced_dax_query


@log_time
def get_report_details(user_query: str, report_input_df: pd.DataFrame) -> dict[str, str]:
    """
    Using Genai to obtain the report details associated with the user query
    based on report definitions.

    Args:
        user_query: query from user to use for generating dax query
        report_input_df: pandas DF with report details

    Returns: relevant report details for the user's query

    """
    query_report_mapping = get_reports_description(report_input_df[["report_id", "description"]])
    report_map_prompt = report_mapping_prompt(user_query, query_report_mapping)

    # TODO: Refactor reporting to use 3.5
    # TODO: Add pydantic parsing method to ensure it is in json format

    try:
        model_name = key_facts_config["common_config"]["model"]["model_name"]
        log.info("Generating dashboard mapping with %s.", model_name)
        report_id = json.loads(
            generate_chat_response_with_chain(
                report_map_prompt,
                model=model_name,
            ),
        )["report_id"]
    except JSONDecodeError:
        turbo_model_name = key_facts_config["common_config"]["model"]["model_name_turbo"]
        log.info("Generating dashboard mapping with %s.", turbo_model_name)
        report_id = json.loads(
            generate_chat_response_with_chain(
                report_map_prompt,
                model=turbo_model_name,
                response_format="json_mode",
            ),
        )["report_id"]

    if report_id in report_input_df["report_id"].values:
        return report_input_df[report_input_df["report_id"] == report_id].iloc[0]

    log.info("Could not find any relevant reports for the user Question!")
    return {}


@log_time
def get_formatted_output(
    query_title: str | None = None,
    report_id: str | None = None,
    additional_msg: str = "",
    message: str | None = None,
) -> dict[str, Any]:
    """
    Convert acquired data to specified endpoint output format dict.

    Args:
        query_title (str | None): Title associated with the user query.
        report_id (str | None): Report ID associated with the user query.
        additional_msg (str): Default text to introduce the dashboard.
        message (str | None): Message to include, either GenAI generated answer or error message.

    Returns:
        dict[str, Any]: Formatted output with acquired details.
    """
    output: dict[str, Any] = {
        "response_type": "summary",
        "response_prerequisite": "",
        "owner": "ai",
        "message": "",
        "links": [],
        "additional_text": "",
    }

    if message:
        output["message"] = message
        return output

    if query_title and report_id:
        link_details: dict[str, Any] = {
            "type": "powerBI",
            "details": {
                "title": "Key facts - " + query_title + " Dashboard",
                "description": f"{query_title} dashboard provides important data points that can "
                f"help understand an organization's {query_title.lower()} patterns.",
                "reportName": "TechCME Detailed Dashboard V1",
                "pageName": report_id,
            },
        }
        output.update(
            {
                "links": [link_details],
                "additional_text": additional_msg + f"on {query_title.lower()}.",
            },
        )
        return output

    return exception_response(
        response_type="exception",
        message="Ada cannot find what you are looking for at the moment. Please try again later.",
    )


@log_time
def summarize_dax_output(
    dax_output: str,
    question: str,
    category: str,
    preferred_currency: str,
    fixed_query: str,
    sql_query: str= ''
) -> str:
    """
    Summarizes the DAX output based on the provided question, category, and output format.

    Args:
        dax_output (str): The  output from DAX execution in JSON format.
        question (str): The question for which the DAX output is being summarized.
        category (str): The category of the question.
        preferred_currency (str): The preferred_currency for the tenant.

    Returns:
        str: The generated response after processing the DAX output.
    """

    # log.info("Dax output: %s", dax_output)

    try:
        if isinstance(dax_output, pd.DataFrame):
            df_output = pd.DataFrame(dax_output)
        else:
            df_output = pd.DataFrame(json.loads(dax_output))

        df_output = df_output.drop_duplicates()
        df_output.dropna(axis=1, how='all', inplace=True)
        (df_output.drop(columns=["URL"], inplace=True)) if "URL" in df_output.columns else None
        if len(df_output) > key_facts_config["common_config"]["dax_output_limit"]:
            df_output = df_output.sort_values(
                df_output.select_dtypes(include=np.number).columns.tolist(),
                ascending=False,
            )
            output_head = df_output.iloc[
                : key_facts_config["common_config"]["output_top_n"]
            ].to_json()
            output_tail = (
                df_output.iloc[
                    key_facts_config["common_config"]["output_bottom_n"] :  # noqa: E203
                ][df_output.select_dtypes(include=np.number).columns.tolist()]
                .sum()
                .to_json()
            )
        else:
            output_head = df_output.to_json()
            output_tail = None
    except json.decoder.JSONDecodeError:
        output_head = dax_output
        output_tail = None

    generate_dax_response_prompt = dax_response_generation_prompt(
        question=fixed_query,
        category=category,
        preferred_currency=preferred_currency,
        data=output_head,
        sql_query=sql_query

    )
    # import pdb; pdb.set_trace()
    generated_dax_response = generate_chat_response_with_chain(
        generate_dax_response_prompt,
        model=key_facts_config["common_config"]["model"]["model_name"],
    )
    return generated_dax_response


@log_time
def get_kf_response(user_query, category, tenant_id,  preferred_currency="EUR", open_world_response=True):
    """
    Sends the user query to New Key facts model and returns the response.

    Args:
        user_query (str): The  output from DAX execution in JSON format.
        category_configuration: Configuration class
        category (str): The category of the question.

    Returns:
        str: The generated and summarized response after processing the query output.
    """
    # preferred_currency_details = category_configuration.configuration_dict["currency"]
    # preferred_currency = (
    #     ast.literal_eval(preferred_currency_details)["currency"]
    #     if isinstance(preferred_currency_details, str)
    #     else preferred_currency_details["currency"]
    # )
    log.info("preferred currency: %s", preferred_currency)

    
    
    try:
        user_query = (
            user_query.lower() + f" for category {category.lower()} "
            if category.lower() not in user_query.lower()
            else user_query.lower()
        ).replace("?", " ")
        log.info("User query: %s", user_query)
        # * SAI-424 Ticket
        # * Checking if the open_world_response is enabled
        if open_world_response:
            # * Open ADA to answer generic questions
            response = open_world_response_generation(user_query)
            log.debug(f"Response from open world: {response}")
            if response != 'Text2SQL':
                return get_formatted_output(message=response)
        data, sql, fixed_query = asyncio.run(fetch(user_query, tenant_id))
        log.info(f"KF chatbot truncated response to 5 records: {data.shape}")
        if not isinstance(data, pd.DataFrame):  # Ensure data is always a DataFrame
            raise ValueError("Unexpected response format from fetch.")
    except Exception:  # pylint: disable=broad-exception-caught
        log.exception("Exception in fetch")
        return exception_response(
            response_type="exception",
            message="Ada was unable to answer this question, "
            "can you rephrase the question or be more specific?",
        )


    if isinstance(data, pd.DataFrame):
        # Summarize output
        log.info("Summarizing keyfact chatbot response for user.")
        answer = summarize_dax_output(
            data,
            user_query,
            category,
            preferred_currency,
            sql_query=sql,
            fixed_query=fixed_query
        )
        log.info("Summarized response: \n%s", answer)

        return get_formatted_output(message=answer)

    if isinstance(data, pd.DataFrame):
        log.error("KF chatbot error response: %s", data["error"][0])

    return exception_response(
        response_type="exception",
        message="Ada was unable to answer this question, "
        "can you rephrase the question or be more specific?",
    )


@log_time
def run_key_facts(json_file: str, category_configuration: Configuration) -> dict[str, Any]:
    # pylint: disable=too-many-return-statements
    # pylint: disable=too-many-statements
    """
    Run key fact use case
    Based on user query, using GenAI either create Dax query
    or summarize Dax response and identify required reports

    Args:
        json_file: json payload from realtime endpoint
        category_configuration: Configuration class

    Returns:
        Summarized answers or Dax to corresponding input question
    """
    json_data = json.loads(json_file)

    log.info(f"Recieved JSON Object: {json_data}")
    dax_response_code = json_data["dax_response_code"]
    user_query = json_data["user_query"]
    tenant_id = json_data["tenant_id"]
    request_id = json_data["request_id"]
    category = json_data["category"]
    # # * SAI-499 Ticket
    # # * Extract Region and provide it for KF response
    # region = json_data["region"]
    # log.info("Region: %s", region)

    # TODO : update request_id as the primary key for cache table
    log.info("Request ID: %s\nUser query: %s\n", request_id, user_query)

    pg_db_conn = PGConnector(tenant_id=tenant_id)
    sf_client = SnowflakeClient()
    # supported_categories = [
    #     item.lower() for item in category_configuration.get_supported_categories(pg_db_conn)
    # ]

    # TODO: This code is commented on 11th April 2025
    # TODO: This code is useless as it blocks multi-tenant scenarios
    # TODO: SAI-638 https://mckinsey.atlassian.net/browse/SAI-638
    # supported_categories = ['corrugated boards', 'pipe, hose, tube & fittings', 'tools', 'cibc', 'pumps, compressors & parts', 'valves', 'oils, lubricants & greases', 'batteries', 'pumps', 'structural materials, sheets, pipes & fittings', 'bearings', 'tools (clamps, pliers, wrenches, tool kits, etc.)', 'filters/filter media and combo bags', 'chemicals', 'filters', 'motors', 'ppe & safety items', 'hvac and refrigeration', 'marketing svcs']
    # if category.lower() not in supported_categories:
    #     log.error("Category %s is not supported by key facts.", category)
    #     return exception_response(
    #         response_type="exception",
    #         message=f"Selected category {category} is not supported by ada.\
    #         Please select another category to proceed.",
    #     )

    distance_threshold = key_facts_config["common_config"]["distance_threshold"]
    dax_query_view_columns = key_facts_config["common_config"]["dax_query_view_columns"]
    # category_configuration.load_configuration(pg_connector=pg_db_conn, category=category)
    

    if kf_chatbot_config.enabled and dax_response_code != 601:
        return get_kf_response(user_query, category, tenant_id, preferred_currency="EUR")

    if dax_response_code == 400 and dax_response_code != 601:
        log.error("Invalid DAX query")
        # Store in DB with 400 code
        pg_db_conn.update_values(
            table_name="dax_queries",
            values={"execution_status": 400},
            conditions={"request_id": request_id, "user_category": category},
        )
        pg_db_conn.close_connection()

        return exception_response(
            response_type="exception",
            message="Ada was unable to answer this question, "
            "can you rephrase the question or be more specific?",
        )

    if dax_response_code == 403:
        log.error("Could not access PowerBI API")
        # Store in DB with 403 code
        pg_db_conn.update_values(
            table_name="dax_queries",
            values={"execution_status": 403},
            conditions={"request_id": request_id, "user_category": category},
        )
        pg_db_conn.close_connection()

        return exception_response(
            response_type="exception",
            message="Sorry, Ada wasn't be able to access the database now. Please try later!",
        )

    if dax_response_code is not None and dax_response_code not in [200, 601]:
        log.error("Invalid Response - %s", dax_response_code)
        # Store in DB with other code
        pg_db_conn.update_values(
            table_name="dax_queries",
            values={"execution_status": dax_response_code},
            conditions={"request_id": request_id, "user_category": category},
        )
        pg_db_conn.close_connection()

        return exception_response(
            response_type="exception",
            message="Sorry, Ada wasn't able to answer this question for now.",
            # TODO : get back to the most similar questions
        )

    if dax_response_code is None:
        # Perform search for similar queries
        log.info("Searching for similar DAX queries")

        # TODO : Implement Semantic Search using Cache - new PR
        # TODO - Why are we running the queries for exact match - can be avoided!
        # TODO : Get the results for the queries + summariser for better articulation
        # TODO : What if the semantic match gives an incorrect result,
        #  can we get a CTA to capture user input?
        user_query_emb = generate_embeddings_from_string(text=user_query)

        similar_queries = pg_db_conn.search_by_vector_similarity(
            table_name="validated_dax_queries_view",
            query_emb=user_query_emb,
            emb_column_name="user_question_emb",
            num_records=3,
            conditions={"category_name": category},
        )

        similar_queries = pd.DataFrame(
            similar_queries,
            columns=dax_query_view_columns + ["distance"],
        )
        # Exact Match check and return the Dax Query
        if similar_queries["distance"][0] < distance_threshold:
            log.info(
                "Exact question match was found:\n%s",
                similar_queries["dax_query"][0],
            )

            pg_db_conn.insert_values_into_columns(
                tuple_with_columns=(
                    "request_id",
                    "user_category",
                    "user_question",
                    "user_question_emb",
                    "dax_query_custom_filters",
                ),
                list_with_values=(
                    request_id,
                    category,
                    user_query,
                    user_query_emb,
                    similar_queries["dax_query"][0],
                ),
                table_name="dax_queries",
            )

            pg_db_conn.close_connection()
            return {
                "response_type": "dax",
                "response_prerequisite": re.sub(
                    r"'+",
                    "'",
                    similar_queries["dax_query"][0],
                ),
                "owner": "ai",
                "additional_text": "",
                "message": "",
                "links": [],
            }

        # Set few-shot examples based on most similar queries
        log.info("Exact question match was not found")
        few_shot_examples = {
            "few_shot_questions": similar_queries["user_question"],
            "few_shot_query_filtered": similar_queries["dax_query"].map(
                lambda query: re.sub(r"'+", "'", query),
            ),
        }
        log.info(
            "Best matches for few shot training : \n%s",
            few_shot_examples["few_shot_questions"],
        )

        # Generate DAX query
        log.info("Generating DAX query")

        dax_query = generate_dax_query(
            user_query,
            few_shot_examples,
            category,
            category_configuration,
        )
        log.info("Generated DAX code: \n%s", dax_query)

        dax_query_final = enhance_dax_query(
            dax_query,
            pg_db_conn,
            category,
        )
        log.info("Enhanced DAX code: \n%s", dax_query_final)

        # Write generation results to the DB
        pg_db_conn.insert_values_into_columns(
            tuple_with_columns=(
                "request_id",
                "user_category",
                "user_question",
                "user_question_emb",
                "dax_query_custom_filters",
            ),
            list_with_values=(
                request_id,
                category,
                user_query,
                user_query_emb,
                dax_query_final.replace("'", "''"),
            ),
            table_name="dax_queries",
        )
        pg_db_conn.close_connection()

        return {
            "response_type": "dax",
            "response_prerequisite": dax_query_final,
            "owner": "ai",
            "additional_text": "",
            "message": "",
            "links": [],
        }

    if dax_response_code == 200:
        preferred_currency_details = category_configuration.configuration_dict["currency"]
        preferred_currency = (
            ast.literal_eval(preferred_currency_details)["currency"]
            if isinstance(preferred_currency_details, str)
            else preferred_currency_details["currency"]
        )
        log.info("preferred currency: %s", preferred_currency)

        # Summarize output
        log.info("Summarizing DAX response for user.")
        answer = summarize_dax_output(
            json_data["dax_response"],
            user_query,
            category,
            preferred_currency,
        )
        log.info("Summarized response: \n%s", answer)

        pg_db_conn.update_values(
            table_name="dax_queries",
            values={
                "execution_status": 200,
                "execution_output": json_data["dax_response"],
                "summarised_output": answer,
            },
            conditions={"request_id": request_id, "user_category": category},
        )
        log.info(
            "DAX queries table updated with execution code = 200 for request_id : %s",
            request_id,
        )

        return get_formatted_output(message=answer)

    if dax_response_code == 601:
        log.info("Fetching related report and title.")
        report_input_df = pd.DataFrame(
            sf_client.select_records_with_filter(
                table_name="DATA.dashboard_monitoring",
                filtered_columns=key_facts_config["common_config"]["dashboard"]["reporting_cols"],
                filter_condition=f"category_name = '{category}'",
            ),
            columns=key_facts_config["common_config"]["dashboard"]["reporting_cols"],
        )

        report_details = get_report_details(user_query, report_input_df)

        if len(report_details) == 0:
            return get_formatted_output(
                query_title=key_facts_config["common_config"]["dashboard"][
                    "default_dashboard_title"
                ],
                report_id=key_facts_config["common_config"]["dashboard"]["default_report_id"],
                additional_msg=key_facts_config["common_config"]["dashboard"][
                    "dashboard_not_found_msg"
                ],
            )

        report_id = report_details["report_id"]
        query_title = report_details["title"]

        return get_formatted_output(
            query_title=query_title,
            report_id=report_id,
            additional_msg=key_facts_config["common_config"]["dashboard"]["additional_msg"],
        )

    pg_db_conn.close_connection()
    return exception_response(
        response_type="exception",
        message=f"Ada unable to parse the response type. Please contact support at Ada. Info:"
        f"\nDAX response code: {dax_response_code}"
        f"\nUser query: {user_query}"
        f"\nCategory: {category}",
    )
