"""
this module helps to answer user question from reference document provided
for answering user question it uses multiple workflow like
1. asking question with top k related docs
2. asking question with all reference docs
3. asking grammatically correct question
4. asking question with few shots chain of thoughts example
5. asking question with step-by-step approach
6. asking similar question

it returns LLM response once answer is useful and related to question
"""

import re
from typing import Any

from langchain_core.vectorstores import VectorStore

from ada.components.llm_models.generic_calls import (
    create_qa_chain,
    generate_chat_response_with_chain,
    run_qa_chain,
)
from ada.components.llm_models.model_base import Model
from ada.components.prompts.prompts import (
    check_answer_prompt,
    create_grammar_check_message,
    create_similar_question_message,
    create_step_by_step_template,
    doc_q_and_a_prompt,
    doc_qna_step_by_step_sys_prompt,
    qna_chain_template,
)
from ada.utils.logs.logger import get_logger
from ada.utils.logs.time_logger import log_time
from ada.utils.metrics.similarity import get_similarity_score

log = get_logger("document_qna.py")


def answer_is_helpful(question: str, response: str, model: str | Model = "gpt-4o") -> bool:
    """Content check on answer generated by model
    Args:
        question (str): user question
        response (str): probable answer to question
    Returns:
        (bool) true if answer is helpful in answering question false otherwise
    """
    sentence = "ANSWER IS NOT FOUND"
    if sentence in response.upper() or (
        get_similarity_score(sentence, response, model="en_core_web_lg") > 0.8
    ):
        return False
    prompt = check_answer_prompt(question, response)
    model_val = model.obj if isinstance(model, Model) else model
    answer = generate_chat_response_with_chain(prompt=prompt, model=model_val).upper()
    log.info("answer helpful response %s", answer)
    if "NO" in answer or (get_similarity_score("NO", answer, model="en_core_web_lg") > 0.8):
        return False
    log.info("question: %s \n response: %s", question, answer)
    return True


def question_is_correct(question: str, model: str | Model, temperature: float) -> str:
    """Check Factual correctness of question
    this function checks whether user question is grammatically correct or not
    it returns original question incase question is grammatically correct
    or returns grammatically correct question generated by LLM to user

    Args:
        question (str): user question
        model (str): model name ex. "gpt-35-turbo"
        temperature (float): model parameter

    Returns:
        (str): grammatically correct question or original question
    """
    prompt = create_grammar_check_message(question)
    log.info("prompt request is %s", prompt)
    model_val = model.obj if isinstance(model, Model) else model
    response = generate_chat_response_with_chain(
        prompt=prompt,
        model=model_val,
        temperature=temperature,
    )
    sentence = "GRAMMATICALLY CORRECT"
    if sentence in response.upper() or (
        get_similarity_score(sentence, response, model="en_core_web_lg") > 0.8
    ):
        return question
    return response


def generate_similar_question(question: str, model: str | Model = "gpt-4o") -> str:
    """create similar question

    Args:
        question(str): user question
        model(str | Model): model name ex. "gpt-35-turbo"
    Returns:
        (str): similar question
    """
    prompt = create_similar_question_message(question)
    model_val = model.obj if isinstance(model, Model) else model
    return generate_chat_response_with_chain(prompt=prompt, model=model_val)


def ask_document_question(
    question: str,
    vectorstore: VectorStore,
    search_k: int = 20,
    include_sources: bool = True,
    model: str | Model = "gpt-35-turbo",
    model_host: str = "",
    temperature: float = 0.0,
    **kwargs: Any,
) -> dict[str, str]:
    """main function in creating answer from question and related documents in vectorstore

    Args:
        question (str): user question
        vectorstore (Vectorstore): vectorstore object from related document
        search_k (int): top k documents that you would like to use for answering question
        include_sources (bool): controls whether sources are included in DocQnA
        model (str | Model): model name ex. "gpt-35-turbo"
        model_host (str): model host name ex. "openai-chat"
        temperature (float): model parameter
        kwargs (Any): Additional keyword arguments
    Returns:
        dictionary with "answer" and "sources" for a question from relevant documents
    """
    log.info("ask_document_question function is called %d", len(kwargs))

    retriever = vectorstore.as_retriever(search_kwargs={"k": search_k})
    grammar_correct_que = question_is_correct(question, model, temperature)
    prompt = doc_q_and_a_prompt(model_host=model_host, include_sources=include_sources)
    human_chain_prompt = doc_q_and_a_prompt(
        model_host=model_host,
        include_sources=include_sources,
        human_prompt_template=qna_chain_template(),
    )
    step_prompt = doc_q_and_a_prompt(
        model_host=model_host,
        include_sources=include_sources,
        human_prompt_template=create_step_by_step_template(),
    )
    steps = [
        {
            "step_name": "STEP 1. Find answer from top documents",
            "retriever": retriever,
            "question": question,
            "prompt": prompt,
        },
        {
            "step_name": "STEP 2. Ask grammatically correct question",
            "retriever": retriever,
            "question": grammar_correct_que,
            "prompt": prompt,
        },
        {
            "step_name": "STEP 3. Ask question with few shots example "
            "of chain of thoughts questions",
            "retriever": retriever,
            "question": grammar_correct_que,
            "prompt": human_chain_prompt,
        },
        {
            "step_name": "STEP 4. Ask question with step by step thinking template",
            "retriever": retriever,
            "question": grammar_correct_que,
            "prompt": step_prompt,
        },
        {
            "step_name": "STEP 5. Ask similar question",
            "retriever": retriever,
            "question": generate_similar_question(question, model=model),
            "prompt": prompt,
        },
    ]

    model_val = model.obj if isinstance(model, Model) else model

    for step_val in steps:
        chain = create_qa_chain(
            retriever=step_val["retriever"],
            prompt=step_val["prompt"],
            model=model_val,
            temperature=temperature,
            return_sources=True,
        )
        response = run_qa_chain(chain, step_val["question"])
        answer = response["answer"]
        log.info("\n Answer with %s is: %s \n", step_val["step_name"], answer)
        if "SO THE FINAL ANSWER IS:" in answer.upper():
            answer = [x for x in answer.split("\n") if x != ""][-1].replace(
                "So the final answer is: ",
                "",
            )
        if answer_is_helpful(step_val["question"], answer, model=model):
            response["answer"] = answer
            log.info(
                "Answer at  %s is correct and responding the same as user answer",
                step_val["step_name"],
            )
            return response

    return {
        "answer": "We were unable to find the answer you are looking for. \
            Could you provide some additional information to help in locating the details",
        "sources": "",
    }


def extract_links(answer: str) -> tuple[str, list[dict[str, Any]]]:
    """
    Extracts Markdown links from text, returning the text with links removed but display text
    preserved. Also returns a dictionary mapping display text to URLs.

    Args:
        answer (str): Text containing Markdown links.

    Returns:
        tuple[str, list[dict[str, Any]]]:
            Modified text and a list of dictionaries containing details about the links.
    """
    pattern = r"\[([^\]]+)\]\((https?://[^\)]+)\)"
    text_links = re.findall(pattern, answer)
    links = [
        {
            "type": "source_ai",
            "details": {
                "title": re.search(r"/([^/]+)/?$", link)
                .group(1)  # type: ignore
                .capitalize()
                .replace("-", " "),
                "link": link,
            },
        }
        for _, link in text_links
    ]

    return re.sub(pattern, r"\1", answer), links


@log_time
def ask_document_question_v2(
    question: str,
    vectorstore: VectorStore,
    search_k: int = 20,
    include_sources: bool = True,
    model: str | Model = "gpt-35-turbo",
    model_host: str = "",
    temperature: float = 0.0,
    **kwargs: Any,
) -> dict[str, str]:
    """main function in creating answer from question and related documents in vectorstore

    Args:
        question (str): user question
        vectorstore (VectorStore): vectorstore object from related document
        search_k (int): top k documents that you would like to use for answering question
        include_sources (bool): controls whether sources are included in DocQnA
        model (str): model name ex. "gpt-35-turbo"
        model_host (str): model host name ex. "openai-chat"
        temperature (float): model parameter
    Returns:
        (dict[str, str]): dictionary with "answer" and "sources" for a question from
        relevant documents
    """
    log.info("ask_document_question function called %d", len(kwargs))
    retriever = vectorstore.as_retriever(search_kwargs={"k": search_k})
    sys_prompt_template = doc_qna_step_by_step_sys_prompt()
    prompt = doc_q_and_a_prompt(
        sys_prompt_template,
        model_host=model_host,
        include_sources=include_sources,
    )
    chain = create_qa_chain(
        retriever=retriever,
        prompt=prompt,
        model=model.obj if isinstance(model, Model) else model,
        temperature=temperature,
        return_sources=True,
    )
    response = run_qa_chain(chain, question)
    log.info("response from ask document question v2 version: %s", response["answer"])
    answer = response["answer"]
    if answer_is_helpful(question, answer, model=model):
        answer, links = extract_links(answer)
        response["answer"] = answer
        response["links"] = links
        return response
    return {
        "answer": "answer not found",
        "sources": "",
    }
